{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAMEL: https://github.com/camel-ai/camel\n",
    "\n",
    "The original demo provided by CAMEL: https://colab.research.google.com/drive/1AzP33O8rnMW__7ocWJhVBXjKziJXPtim?usp=sharing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/camel-ai/camel.git@v0.1.0\n",
      "  Cloning https://github.com/camel-ai/camel.git (to revision v0.1.0) to /tmp/pip-req-build-plxlftxf\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/camel-ai/camel.git /tmp/pip-req-build-plxlftxf\n",
      "  Running command git checkout -q bda4bf43bb03092936c2c0316aee9ff96aa551bf\n",
      "  Resolved https://github.com/camel-ai/camel.git to commit bda4bf43bb03092936c2c0316aee9ff96aa551bf\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/qxw5138/miniconda3/envs/myflaml/lib/python3.9/site-packages (from camel==0.1.0) (1.23.5)\n",
      "Requirement already satisfied: openai in /home/qxw5138/miniconda3/envs/myflaml/lib/python3.9/site-packages (from camel==0.1.0) (0.27.4)\n",
      "Requirement already satisfied: tenacity in /home/qxw5138/.local/lib/python3.9/site-packages (from camel==0.1.0) (8.1.0)\n",
      "Collecting tiktoken (from camel==0.1.0)\n",
      "  Downloading tiktoken-0.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting colorama (from camel==0.1.0)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /home/qxw5138/miniconda3/envs/myflaml/lib/python3.9/site-packages (from openai->camel==0.1.0) (2.28.2)\n",
      "Requirement already satisfied: tqdm in /home/qxw5138/miniconda3/envs/myflaml/lib/python3.9/site-packages (from openai->camel==0.1.0) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in /home/qxw5138/.local/lib/python3.9/site-packages (from openai->camel==0.1.0) (3.8.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/qxw5138/miniconda3/envs/myflaml/lib/python3.9/site-packages (from tiktoken->camel==0.1.0) (2022.10.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/qxw5138/miniconda3/envs/myflaml/lib/python3.9/site-packages (from requests>=2.20->openai->camel==0.1.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/qxw5138/miniconda3/envs/myflaml/lib/python3.9/site-packages (from requests>=2.20->openai->camel==0.1.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/qxw5138/miniconda3/envs/myflaml/lib/python3.9/site-packages (from requests>=2.20->openai->camel==0.1.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/qxw5138/miniconda3/envs/myflaml/lib/python3.9/site-packages (from requests>=2.20->openai->camel==0.1.0) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/qxw5138/miniconda3/envs/myflaml/lib/python3.9/site-packages (from aiohttp->openai->camel==0.1.0) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/qxw5138/.local/lib/python3.9/site-packages (from aiohttp->openai->camel==0.1.0) (6.0.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/qxw5138/.local/lib/python3.9/site-packages (from aiohttp->openai->camel==0.1.0) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/qxw5138/.local/lib/python3.9/site-packages (from aiohttp->openai->camel==0.1.0) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/qxw5138/.local/lib/python3.9/site-packages (from aiohttp->openai->camel==0.1.0) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/qxw5138/.local/lib/python3.9/site-packages (from aiohttp->openai->camel==0.1.0) (1.3.1)\n",
      "Building wheels for collected packages: camel\n",
      "  Building wheel for camel (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for camel: filename=camel-0.1.0-py3-none-any.whl size=35372 sha256=9b4f272022f12caf0a83f326b046d011b492cf8825bc2464348247fddc766b2f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ims98tkh/wheels/e7/0d/00/c09d0b4eeec05ad560f694a92cfa5d73d50c3f4603b5ceb518\n",
      "Successfully built camel\n",
      "Installing collected packages: colorama, tiktoken, camel\n",
      "Successfully installed camel-0.1.0 colorama-0.4.6 tiktoken-0.4.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/camel-ai/camel.git@v0.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"YOUR_OPENAI_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mOriginal task prompt:\n",
      "Design a custom game using pygame\n",
      "\n",
      "\u001b[36mSpecified task prompt:\n",
      "Create a specialized AI companion that assists gamers in exploring and uncovering secret quests and hidden treasures within a virtual game world, providing real-time hints and strategies tailored to the player's gaming style and preferences.\n",
      "\n",
      "\u001b[34mAI User:\n",
      "\n",
      "Instruction: Create a function to generate a random hint for the player.\n",
      "Input: None\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mAI Assistant:\n",
      "\n",
      "Solution: \n",
      "\n",
      "To create a function that generates a random hint for the player, we can use the random module in Python. Here's an example implementation:\n",
      "\n",
      "```python\n",
      "import random\n",
      "\n",
      "def generate_random_hint():\n",
      "    hints = [\n",
      "        \"Try exploring the northern part of the map.\",\n",
      "        \"Check the abandoned house for a hidden passage.\",\n",
      "        \"Use your special ability to reveal hidden objects.\",\n",
      "        \"Talk to the NPC in the town square for a clue.\",\n",
      "        \"Look for a symbol on the wall near the dungeon entrance.\"\n",
      "    ]\n",
      "    random_hint = random.choice(hints)\n",
      "    return random_hint\n",
      "```\n",
      "\n",
      "In this solution, we define a function called `generate_random_hint()` that returns a randomly selected hint from a list of predefined hints. Each time the function is called, it will return a different hint.\n",
      "\n",
      "Next request.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34mAI User:\n",
      "\n",
      "Instruction: Create a function to analyze the player's gaming style and preferences.\n",
      "Input: None\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mAI Assistant:\n",
      "\n",
      "Solution:\n",
      "\n",
      "To create a function that analyzes the player's gaming style and preferences, we can prompt the player with a series of questions and store their responses. Here's an example implementation:\n",
      "\n",
      "```python\n",
      "def analyze_gaming_style():\n",
      "    preferences = {}\n",
      "\n",
      "    print(\"Please answer the following questions to help us analyze your gaming style and preferences:\")\n",
      "\n",
      "    preferences[\"difficulty\"] = input(\"What difficulty level do you usually prefer? (Easy, Medium, Hard): \")\n",
      "    preferences[\"playstyle\"] = input(\"Do you prefer a more aggressive or defensive playstyle? (Aggressive, Defensive): \")\n",
      "    preferences[\"genre\"] = input(\"What is your favorite game genre? \")\n",
      "\n",
      "    return preferences\n",
      "```\n",
      "\n",
      "In this solution, we define a function called `analyze_gaming_style()` that prompts the player with questions about their gaming style and preferences. The player's responses are stored in a dictionary called `preferences`, with keys representing different aspects such as difficulty, playstyle, and genre.\n",
      "\n",
      "The function then returns the `preferences` dictionary, which can be used by the AI companion to tailor hints and strategies based on the player's preferences.\n",
      "\n",
      "Next request.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34mAI User:\n",
      "\n",
      "Instruction: Create a function to provide real-time hints based on the player's gaming style and preferences.\n",
      "Input: The player's gaming style and preferences (dictionary).\n",
      "\n",
      "\n",
      "\n",
      "\u001b[32mAI Assistant:\n",
      "\n",
      "Solution:\n",
      "\n",
      "To create a function that provides real-time hints based on the player's gaming style and preferences, we can use the information stored in the preferences dictionary. Here's an example implementation:\n",
      "\n",
      "```python\n",
      "def provide_real_time_hint(preferences):\n",
      "    hints = {\n",
      "        \"Easy\": \"Consider exploring more challenging areas to find hidden treasures.\",\n",
      "        \"Medium\": \"Try interacting with different NPCs to uncover secret quests.\",\n",
      "        \"Hard\": \"Look for hidden paths and shortcuts to progress further in the game.\",\n",
      "        \"Aggressive\": \"Focus on offensive abilities and take down enemies quickly.\",\n",
      "        \"Defensive\": \"Utilize defensive tactics and strategies to survive tough encounters.\",\n",
      "        \"Genre\": \"In your favorite genre, there might be hidden easter eggs or references to discover.\"\n",
      "    }\n",
      "\n",
      "    hint = \"\"\n",
      "\n",
      "    for key, value in preferences.items():\n",
      "        if value in hints:\n",
      "            hint += hints[value] + \" \"\n",
      "\n",
      "    return hint.strip()\n",
      "```\n",
      "\n",
      "In this solution, we define a function called `provide_real_time_hint()` that takes the player's gaming style and preferences as input. We have a dictionary called `hints` that maps different preferences to corresponding hints.\n",
      "\n",
      "The function iterates over the preferences dictionary and checks if the value exists in the `hints` dictionary. If it does, the corresponding hint is added to the `hint` variable. Finally, the function returns the concatenated hints as a single string.\n",
      "\n",
      "This function can be called by the AI companion whe"
     ]
    }
   ],
   "source": [
    "from colorama import Fore\n",
    "\n",
    "from camel.agents import RolePlaying\n",
    "from camel.utils import print_text_animated\n",
    "\n",
    "task_prompt = \"Design a custom game using pygame\"\n",
    "print(Fore.YELLOW + f\"Original task prompt:\\n{task_prompt}\\n\")\n",
    "role_play_session = RolePlaying(\"Computer Programmer\", \"Gamer\", task_prompt)\n",
    "print(Fore.CYAN + f\"Specified task prompt:\\n{role_play_session.task_prompt}\\n\")\n",
    "\n",
    "chat_turn_limit, n = 10, 0\n",
    "assistant_msg, _ = role_play_session.init_chat()\n",
    "while n < chat_turn_limit:\n",
    "    n += 1\n",
    "    (assistant_msg, _, _), (user_msg, _, _) = role_play_session.step(assistant_msg)\n",
    "    print_text_animated(Fore.BLUE + f\"AI User:\\n\\n{user_msg.content}\\n\\n\")\n",
    "    print_text_animated(Fore.GREEN + f\"AI Assistant:\\n\\n{assistant_msg.content}\\n\\n\")\n",
    "    if \"<CAMEL_TASK_DONE>\" in user_msg.content:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myflaml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
